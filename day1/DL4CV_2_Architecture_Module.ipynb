{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "DL4CV - 2 - Architecture Module.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "nf8b112z_skA",
        "9CBOFozy_skD",
        "bRu37RNb_skG",
        "5tU4uqdY_skW"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteoalberti/Lectures_AdvCV_Experis2020/blob/main/day1/DL4CV_2_Architecture_Module.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxbHHmkf_siR"
      },
      "source": [
        "![](https://github.com/matteoalberti/Lectures_introCV_Experis2020/blob/main/images/intro.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sELgQ5b_siS"
      },
      "source": [
        "# **Welcome!**\n",
        "\n",
        "## Introduction to Machine Learning for Computer Vision\n",
        "\n",
        "\n",
        "\n",
        "## **Lecturer :** Matteo Alberti\n",
        "\n",
        "![](data:image/jpeg;base64,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)\n",
        "\n",
        "*Contacts :* https://www.linkedin.com/in/matteo-alberti-170493/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp5gD9sU_siT"
      },
      "source": [
        "# Summary\n",
        "\n",
        "\n",
        "- <font color=C24024>**Best Practices & Basic Architecture** </font> : [LeNet]\n",
        "\n",
        "- <font color=CA4A2F>**Train a Convolutional Networks with Keras** </font> : \n",
        "\n",
        "    - <font color=E35F2A>**Work with Model** </font>\n",
        "\n",
        "    - <font color=EF8932>**Work with data** </font> : [Visualize inside CNN]\n",
        "\n",
        "- <font color=F4C52D>**Exercises & Tips** </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKw6CAGn_siU"
      },
      "source": [
        "#### Load Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5okCFTqa_siV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b880015a-54d0-4ef6-846c-88e72fe90b01"
      },
      "source": [
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import argparse\n",
        "import time\n",
        "import gc\n",
        "import datetime\n",
        "import platform\n",
        "import numpy as np\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "kerasBKED = os.environ[\"KERAS_BACKEND\"] \n",
        "\n",
        "#Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "import seaborn as sns\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "try:\n",
        "    import pydot_ng as pydot\n",
        "except ImportError:\n",
        "    pydot = None\n",
        "    \n",
        "try:\n",
        "    os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
        "except:\n",
        "    pass\n",
        "\n",
        "#Sklearn ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "\n",
        "#Keras Imports\n",
        "\n",
        "import tensorflow as tf\n",
        "import sklearn.model_selection as model_selection\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print('TF Version : ',tf.__version__)\n",
        "print('Python Version : ', platform.python_version())"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF Version :  2.3.0\n",
            "Python Version :  3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lO31w7ue_sib"
      },
      "source": [
        "### Load Cifar10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfm5Aw6G_sib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb043233-a461-485e-ca68-207c083341a0"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV_0hnVeP3QT"
      },
      "source": [
        "![](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/07/Depiction-of-CNN-Model-for-Accelerompter-Data.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDVgTi3__sis"
      },
      "source": [
        "##### Normalize data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3pBq_Mz_sit"
      },
      "source": [
        "#The range for each individual colour is 0-255\n",
        "x_train = x_train.astype('float32')/255 \n",
        "x_test = x_test.astype('float32')/255"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMTbJ5JS_six"
      },
      "source": [
        "### Define HyperParameters & CNN Architecture\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgGrSQss_siy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d66f93ce-42f8-42fa-abef-c8698387b887"
      },
      "source": [
        "#Parameters\n",
        "import sys;import argparse; sys.argv=['']; del sys\n",
        "parser = argparse.ArgumentParser(description=\"CNN\")\n",
        "parser.add_argument('--epochs', default=20, type=int)\n",
        "parser.add_argument('--iter', default=100, type=int)\n",
        "parser.add_argument('--batch_size', default=128, type=int)\n",
        "parser.add_argument('--lr', default=0.001, type=float)\n",
        "\n",
        "#For VGG\n",
        "parser.add_argument('--weight_decay', default=0.0001, type=float)\n",
        "parser.add_argument('--dropout', default=0.5, type=float)\n",
        "\n",
        "\n",
        "parser.add_argument('--height', default=32, type=int)\n",
        "parser.add_argument('--width', default=32, type=int)\n",
        "parser.add_argument('--channel', default=3, type=int)\n",
        "parser.add_argument('--classes', default=10, type=int)\n",
        "\n",
        "#FOR RESNET\n",
        "parser.add_argument('--stack_n', type=int, default=25, metavar='NUMBER',\n",
        "                help='stack number n, total layers = 6 * n + 2 (default: 5)')\n",
        "\n",
        "parser.add_argument('--train', default=False)\n",
        "args = parser.parse_args()\n",
        "\n",
        "layers_res = 6 * args.stack_n + 2\n",
        "parser.add_argument('--layers_res', default=layers_res)\n",
        "\n",
        "#Extras\n",
        "parser.add_argument('--early_stop', default=3)\n",
        "\n",
        "\n",
        "args = parser.parse_args()\n",
        "\n",
        "print(args)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(batch_size=128, channel=3, classes=10, dropout=0.5, early_stop=3, epochs=20, height=32, iter=100, layers_res=152, lr=0.001, stack_n=25, train=False, weight_decay=0.0001, width=32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDNeEziX_si4"
      },
      "source": [
        "### Baseline Convolutional architecture in Keras : [LeNet]\n",
        "\n",
        "\n",
        "![](https://irenelizihui.files.wordpress.com/2016/03/tf43.png)\n",
        "\n",
        "***Commented VERSION***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFgEZmMN_si5"
      },
      "source": [
        "def build_Lenet(height,width,channel,classes):\n",
        "    \n",
        "    model = tf.keras.Sequential()\n",
        "    \n",
        "    #Features Extractor\n",
        "    model.add(tf.keras.layers.Conv2D(6, (5, 5), \n",
        "                     padding='valid', \n",
        "                     activation = 'relu', \n",
        "                     kernel_initializer='he_normal', #https://keras.io/initializers/#randomnormal\n",
        "                     input_shape=(height,width,channel)))\n",
        "    \n",
        "    \"\"\"    \n",
        "    **Valid** -> without padding\n",
        "    \n",
        "    inputs:         1  2  3  4  5  6  7  8  9  10 11 (12 13)\n",
        "                      |________________|                dropped\n",
        "                                     |_________________|\n",
        "                                     \n",
        "   **Same** -> with zero padding\n",
        "   \n",
        "                pad|                                      |pad\n",
        "   inputs:      0 |1  2  3  4  5  6  7  8  9  10 11 12 13|0  0\n",
        "               |________________|\n",
        "                              |_________________|\n",
        "                                             |________________|\n",
        "                                     \n",
        "    \"\"\"\n",
        "    \n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(tf.keras.layers.Conv2D(16, (5, 5), padding='valid', \n",
        "                     activation = 'relu', \n",
        "                     kernel_initializer='he_normal'))\n",
        "    \n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)))\n",
        "    \n",
        "    model.add(tf.keras.layers.Flatten()) # unrolls the values beginning at the last dimension\n",
        "    \n",
        "    \"\"\"\n",
        "    We need to convert the output of the convolutional part of the CNN \n",
        "    into a 1D feature vector during the classification part\n",
        "    \n",
        "    It gets the output of the convolutional layers, \n",
        "    flattens all its structure to create a single long \n",
        "    feature vector to be used by the dense layer \n",
        "    for the final classification\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    \n",
        "    #Classification\n",
        "    model.add(tf.keras.layers.Dense(120, activation = 'relu', kernel_initializer='he_normal'))\n",
        "    model.add(tf.keras.layers.Dense(84, activation = 'relu', kernel_initializer='he_normal'))\n",
        "    model.add(tf.keras.layers.Dense(classes, activation = 'softmax', \n",
        "                    kernel_initializer='he_normal'))\n",
        "    \n",
        "    #Compile & Optimizers\n",
        "    sgd = tf.keras.optimizers.SGD(lr=.1, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer=sgd, metrics=['accuracy'])\n",
        "    \n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8mgBOOjG79k"
      },
      "source": [
        "***Summary***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U1gic96FfJU"
      },
      "source": [
        "def build_Lenet(height,width,channel,classes):\n",
        "    \n",
        "    return tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(6, (5, 5), \n",
        "                     padding='valid', \n",
        "                     activation = 'relu', \n",
        "                     kernel_initializer='he_normal',\n",
        "                     input_shape=(height,width,channel)),\n",
        "\n",
        "     \n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(16, (5, 5), padding='valid', \n",
        "                     activation = 'relu', \n",
        "                     kernel_initializer='he_normal'),\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(120, activation = 'relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(84, activation = 'relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(classes, activation = 'softmax', \n",
        "                    kernel_initializer='he_normal')])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arODtwrx_si9"
      },
      "source": [
        "#### Extra Notes:\n",
        "\n",
        "    - Why do we need activation function on convolutions?\n",
        "\n",
        "The purpose of activation functions is mainly to add non-linearity to the network, which otherwise would be only a linear model. A convolutional layer by itself is linear exactly like the fully connected layer.\n",
        "\n",
        "In fact if you visualize each pixel of the input and output images as a node, then you would obtain a fully connected layer with a lot less edges. Or, in other words, the input values get multiplied by coefficients. Following a complex logic, but nothing more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJnm4WnP_si9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2cea045-47a3-4cd2-f343-1411185b2466"
      },
      "source": [
        "# build network\n",
        "lenet_base = build_Lenet(height=args.height, \n",
        "                         width=args.width, \n",
        "                         channel=args.channel, \n",
        "                         classes=args.classes)\n",
        "\n",
        "lenet_base.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "lenet_base.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 6)         456       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 400)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 120)               48120     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 62,006\n",
            "Trainable params: 62,006\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG5qVmbf_sjD"
      },
      "source": [
        "### We can use also the following code to provide a beautiful representation of our architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DVaGWla_sjG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 886
        },
        "outputId": "80dd5113-8447-459c-cdf3-96fc5be945ca"
      },
      "source": [
        "SVG(model_to_dot(lenet_base, show_shapes=True, \n",
        "             show_layer_names=True, \n",
        "             rankdir='TB', dpi=65 ).create(prog='dot', \n",
        "                                  format='svg'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"649pt\" viewBox=\"0.00 0.00 386.00 719.00\" width=\"348pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(.9028 .9028) rotate(0) translate(4 715)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-715 382,-715 382,4 -4,4\" stroke=\"transparent\"/>\n<!-- 139875530445992 -->\n<g class=\"node\" id=\"node1\">\n<title>139875530445992</title>\n<polygon fill=\"none\" points=\"25,-664.5 25,-710.5 353,-710.5 353,-664.5 25,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"109.5\" y=\"-683.8\">conv2d_input: InputLayer</text>\n<polyline fill=\"none\" points=\"194,-664.5 194,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"194,-687.5 252,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"223\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"252,-664.5 252,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.5\" y=\"-695.3\">[(?, 32, 32, 3)]</text>\n<polyline fill=\"none\" points=\"252,-687.5 353,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"302.5\" y=\"-672.3\">[(?, 32, 32, 3)]</text>\n</g>\n<!-- 139876602685256 -->\n<g class=\"node\" id=\"node2\">\n<title>139876602685256</title>\n<polygon fill=\"none\" points=\"55,-581.5 55,-627.5 323,-627.5 323,-581.5 55,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114\" y=\"-600.8\">conv2d: Conv2D</text>\n<polyline fill=\"none\" points=\"173,-581.5 173,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"173,-604.5 231,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"202\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"231,-581.5 231,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277\" y=\"-612.3\">(?, 32, 32, 3)</text>\n<polyline fill=\"none\" points=\"231,-604.5 323,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277\" y=\"-589.3\">(?, 28, 28, 6)</text>\n</g>\n<!-- 139875530445992&#45;&gt;139876602685256 -->\n<g class=\"edge\" id=\"edge1\">\n<title>139875530445992-&gt;139876602685256</title>\n<path d=\"M189,-664.3799C189,-656.1745 189,-646.7679 189,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-637.784 189,-627.784 185.5001,-637.784 192.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139875545657864 -->\n<g class=\"node\" id=\"node3\">\n<title>139875545657864</title>\n<polygon fill=\"none\" points=\"11,-498.5 11,-544.5 367,-544.5 367,-498.5 11,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"114\" y=\"-517.8\">max_pooling2d: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"217,-498.5 217,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"217,-521.5 275,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"246\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"275,-498.5 275,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-529.3\">(?, 28, 28, 6)</text>\n<polyline fill=\"none\" points=\"275,-521.5 367,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"321\" y=\"-506.3\">(?, 14, 14, 6)</text>\n</g>\n<!-- 139876602685256&#45;&gt;139875545657864 -->\n<g class=\"edge\" id=\"edge2\">\n<title>139876602685256-&gt;139875545657864</title>\n<path d=\"M189,-581.3799C189,-573.1745 189,-563.7679 189,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-554.784 189,-544.784 185.5001,-554.784 192.5001,-554.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139875545658200 -->\n<g class=\"node\" id=\"node4\">\n<title>139875545658200</title>\n<polygon fill=\"none\" points=\"44,-415.5 44,-461.5 334,-461.5 334,-415.5 44,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-434.8\">conv2d_1: Conv2D</text>\n<polyline fill=\"none\" points=\"177,-415.5 177,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"177,-438.5 235,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"206\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"235,-415.5 235,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-446.3\">(?, 14, 14, 6)</text>\n<polyline fill=\"none\" points=\"235,-438.5 334,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"284.5\" y=\"-423.3\">(?, 10, 10, 16)</text>\n</g>\n<!-- 139875545657864&#45;&gt;139875545658200 -->\n<g class=\"edge\" id=\"edge3\">\n<title>139875545657864-&gt;139875545658200</title>\n<path d=\"M189,-498.3799C189,-490.1745 189,-480.7679 189,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-471.784 189,-461.784 185.5001,-471.784 192.5001,-471.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139875545658872 -->\n<g class=\"node\" id=\"node5\">\n<title>139875545658872</title>\n<polygon fill=\"none\" points=\"0,-332.5 0,-378.5 378,-378.5 378,-332.5 0,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"110.5\" y=\"-351.8\">max_pooling2d_1: MaxPooling2D</text>\n<polyline fill=\"none\" points=\"221,-332.5 221,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"221,-355.5 279,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"250\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"279,-332.5 279,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-363.3\">(?, 10, 10, 16)</text>\n<polyline fill=\"none\" points=\"279,-355.5 378,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"328.5\" y=\"-340.3\">(?, 5, 5, 16)</text>\n</g>\n<!-- 139875545658200&#45;&gt;139875545658872 -->\n<g class=\"edge\" id=\"edge4\">\n<title>139875545658200-&gt;139875545658872</title>\n<path d=\"M189,-415.3799C189,-407.1745 189,-397.7679 189,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-388.784 189,-378.784 185.5001,-388.784 192.5001,-388.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139875545659264 -->\n<g class=\"node\" id=\"node6\">\n<title>139875545659264</title>\n<polygon fill=\"none\" points=\"69,-249.5 69,-295.5 309,-295.5 309,-249.5 69,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"118\" y=\"-268.8\">flatten: Flatten</text>\n<polyline fill=\"none\" points=\"167,-249.5 167,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"167,-272.5 225,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"196\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"225,-249.5 225,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-280.3\">(?, 5, 5, 16)</text>\n<polyline fill=\"none\" points=\"225,-272.5 309,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"267\" y=\"-257.3\">(?, 400)</text>\n</g>\n<!-- 139875545658872&#45;&gt;139875545659264 -->\n<g class=\"edge\" id=\"edge5\">\n<title>139875545658872-&gt;139875545659264</title>\n<path d=\"M189,-332.3799C189,-324.1745 189,-314.7679 189,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-305.784 189,-295.784 185.5001,-305.784 192.5001,-305.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139875545659656 -->\n<g class=\"node\" id=\"node7\">\n<title>139875545659656</title>\n<polygon fill=\"none\" points=\"83,-166.5 83,-212.5 295,-212.5 295,-166.5 83,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129\" y=\"-185.8\">dense: Dense</text>\n<polyline fill=\"none\" points=\"175,-166.5 175,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"175,-189.5 233,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"204\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"233,-166.5 233,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-197.3\">(?, 400)</text>\n<polyline fill=\"none\" points=\"233,-189.5 295,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"264\" y=\"-174.3\">(?, 120)</text>\n</g>\n<!-- 139875545659264&#45;&gt;139875545659656 -->\n<g class=\"edge\" id=\"edge6\">\n<title>139875545659264-&gt;139875545659656</title>\n<path d=\"M189,-249.3799C189,-241.1745 189,-231.7679 189,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-222.784 189,-212.784 185.5001,-222.784 192.5001,-222.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139875545660216 -->\n<g class=\"node\" id=\"node8\">\n<title>139875545660216</title>\n<polygon fill=\"none\" points=\"75.5,-83.5 75.5,-129.5 302.5,-129.5 302.5,-83.5 75.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129\" y=\"-102.8\">dense_1: Dense</text>\n<polyline fill=\"none\" points=\"182.5,-83.5 182.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"182.5,-106.5 240.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"211.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"240.5,-83.5 240.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-114.3\">(?, 120)</text>\n<polyline fill=\"none\" points=\"240.5,-106.5 302.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-91.3\">(?, 84)</text>\n</g>\n<!-- 139875545659656&#45;&gt;139875545660216 -->\n<g class=\"edge\" id=\"edge7\">\n<title>139875545659656-&gt;139875545660216</title>\n<path d=\"M189,-166.3799C189,-158.1745 189,-148.7679 189,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-139.784 189,-129.784 185.5001,-139.784 192.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 139875545660776 -->\n<g class=\"node\" id=\"node9\">\n<title>139875545660776</title>\n<polygon fill=\"none\" points=\"79.5,-.5 79.5,-46.5 298.5,-46.5 298.5,-.5 79.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"133\" y=\"-19.8\">dense_2: Dense</text>\n<polyline fill=\"none\" points=\"186.5,-.5 186.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"186.5,-23.5 244.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"215.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"244.5,-.5 244.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-31.3\">(?, 84)</text>\n<polyline fill=\"none\" points=\"244.5,-23.5 298.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"271.5\" y=\"-8.3\">(?, 10)</text>\n</g>\n<!-- 139875545660216&#45;&gt;139875545660776 -->\n<g class=\"edge\" id=\"edge8\">\n<title>139875545660216-&gt;139875545660776</title>\n<path d=\"M189,-83.3799C189,-75.1745 189,-65.7679 189,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"192.5001,-56.784 189,-46.784 185.5001,-56.784 192.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OdcpVCU_sjM"
      },
      "source": [
        "### What we need for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5Dc85jZ_sjN"
      },
      "source": [
        "%load_ext tensorboard\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpzMsoHG_sjQ"
      },
      "source": [
        "### Start training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEScKHIz_sjQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3b119c-f7a5-4b18-d754-ab043a7f01b2"
      },
      "source": [
        "# start train\n",
        "history_lenet = lenet_base.fit(x=x_train, \n",
        "          y=y_train, \n",
        "          epochs=50,\n",
        "          validation_split=0.2, \n",
        "          callbacks=[tensorboard_callback], verbose=1)\n",
        "\n",
        "# save model\n",
        "#lenet_base.save('./pretrained_model/lenet25.h5')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "   1/1250 [..............................] - ETA: 0s - loss: 3.2956 - accuracy: 0.1562WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
            "Instructions for updating:\n",
            "use `tf.profiler.experimental.stop` instead.\n",
            "   2/1250 [..............................] - ETA: 36s - loss: 2.9449 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0078s vs `on_train_batch_end` time: 0.0469s). Check your callbacks.\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 1.6709 - accuracy: 0.3920 - val_loss: 1.4919 - val_accuracy: 0.4596\n",
            "Epoch 2/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.4034 - accuracy: 0.4959 - val_loss: 1.3876 - val_accuracy: 0.4983\n",
            "Epoch 3/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2920 - accuracy: 0.5348 - val_loss: 1.2911 - val_accuracy: 0.5438\n",
            "Epoch 4/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.2115 - accuracy: 0.5649 - val_loss: 1.2681 - val_accuracy: 0.5480\n",
            "Epoch 5/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.1462 - accuracy: 0.5914 - val_loss: 1.2650 - val_accuracy: 0.5541\n",
            "Epoch 6/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0891 - accuracy: 0.6136 - val_loss: 1.1735 - val_accuracy: 0.5893\n",
            "Epoch 7/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 1.0407 - accuracy: 0.6289 - val_loss: 1.2211 - val_accuracy: 0.5742\n",
            "Epoch 8/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9976 - accuracy: 0.6432 - val_loss: 1.1842 - val_accuracy: 0.5835\n",
            "Epoch 9/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9592 - accuracy: 0.6582 - val_loss: 1.1762 - val_accuracy: 0.5976\n",
            "Epoch 10/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.9212 - accuracy: 0.6708 - val_loss: 1.2302 - val_accuracy: 0.5854\n",
            "Epoch 11/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8839 - accuracy: 0.6841 - val_loss: 1.2227 - val_accuracy: 0.5843\n",
            "Epoch 12/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8475 - accuracy: 0.6982 - val_loss: 1.1728 - val_accuracy: 0.6017\n",
            "Epoch 13/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.8195 - accuracy: 0.7078 - val_loss: 1.2260 - val_accuracy: 0.6022\n",
            "Epoch 14/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7860 - accuracy: 0.7197 - val_loss: 1.2585 - val_accuracy: 0.5857\n",
            "Epoch 15/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7552 - accuracy: 0.7323 - val_loss: 1.2541 - val_accuracy: 0.5934\n",
            "Epoch 16/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.7283 - accuracy: 0.7375 - val_loss: 1.3295 - val_accuracy: 0.5833\n",
            "Epoch 17/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6995 - accuracy: 0.7480 - val_loss: 1.2960 - val_accuracy: 0.5927\n",
            "Epoch 18/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6714 - accuracy: 0.7599 - val_loss: 1.3311 - val_accuracy: 0.5902\n",
            "Epoch 19/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6451 - accuracy: 0.7695 - val_loss: 1.3905 - val_accuracy: 0.5835\n",
            "Epoch 20/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.6206 - accuracy: 0.7791 - val_loss: 1.4735 - val_accuracy: 0.5759\n",
            "Epoch 21/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5961 - accuracy: 0.7861 - val_loss: 1.4308 - val_accuracy: 0.5911\n",
            "Epoch 22/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5784 - accuracy: 0.7938 - val_loss: 1.6112 - val_accuracy: 0.5614\n",
            "Epoch 23/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5514 - accuracy: 0.8012 - val_loss: 1.5327 - val_accuracy: 0.5745\n",
            "Epoch 24/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5346 - accuracy: 0.8066 - val_loss: 1.5740 - val_accuracy: 0.5811\n",
            "Epoch 25/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.5048 - accuracy: 0.8183 - val_loss: 1.6305 - val_accuracy: 0.5765\n",
            "Epoch 26/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4905 - accuracy: 0.8229 - val_loss: 1.7519 - val_accuracy: 0.5648\n",
            "Epoch 27/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4817 - accuracy: 0.8281 - val_loss: 1.7991 - val_accuracy: 0.5658\n",
            "Epoch 28/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4535 - accuracy: 0.8357 - val_loss: 1.7696 - val_accuracy: 0.5654\n",
            "Epoch 29/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4366 - accuracy: 0.8432 - val_loss: 1.8361 - val_accuracy: 0.5709\n",
            "Epoch 30/50\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.4267 - accuracy: 0.8460 - val_loss: 1.8946 - val_accuracy: 0.5680\n",
            "Epoch 31/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.4070 - accuracy: 0.8526 - val_loss: 2.0079 - val_accuracy: 0.5610\n",
            "Epoch 32/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3950 - accuracy: 0.8584 - val_loss: 2.0031 - val_accuracy: 0.5690\n",
            "Epoch 33/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3860 - accuracy: 0.8606 - val_loss: 2.1305 - val_accuracy: 0.5606\n",
            "Epoch 34/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3605 - accuracy: 0.8693 - val_loss: 2.1364 - val_accuracy: 0.5680\n",
            "Epoch 35/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3562 - accuracy: 0.8715 - val_loss: 2.1935 - val_accuracy: 0.5706\n",
            "Epoch 36/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3408 - accuracy: 0.8749 - val_loss: 2.3460 - val_accuracy: 0.5555\n",
            "Epoch 37/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3370 - accuracy: 0.8779 - val_loss: 2.3323 - val_accuracy: 0.5641\n",
            "Epoch 38/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3259 - accuracy: 0.8815 - val_loss: 2.4106 - val_accuracy: 0.5595\n",
            "Epoch 39/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3134 - accuracy: 0.8870 - val_loss: 2.5104 - val_accuracy: 0.5566\n",
            "Epoch 40/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.3112 - accuracy: 0.8862 - val_loss: 2.5478 - val_accuracy: 0.5514\n",
            "Epoch 41/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2957 - accuracy: 0.8925 - val_loss: 2.6264 - val_accuracy: 0.5624\n",
            "Epoch 42/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2864 - accuracy: 0.8960 - val_loss: 2.6578 - val_accuracy: 0.5554\n",
            "Epoch 43/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2824 - accuracy: 0.8970 - val_loss: 2.7228 - val_accuracy: 0.5609\n",
            "Epoch 44/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2837 - accuracy: 0.8972 - val_loss: 2.7692 - val_accuracy: 0.5484\n",
            "Epoch 45/50\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.2701 - accuracy: 0.9018 - val_loss: 2.7742 - val_accuracy: 0.5602\n",
            "Epoch 46/50\n",
            "1250/1250 [==============================] - 5s 4ms/step - loss: 0.2576 - accuracy: 0.9055 - val_loss: 2.9395 - val_accuracy: 0.5468\n",
            "Epoch 47/50\n",
            "1250/1250 [==============================] - 4s 4ms/step - loss: 0.2615 - accuracy: 0.9043 - val_loss: 2.9159 - val_accuracy: 0.5521\n",
            "Epoch 48/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2520 - accuracy: 0.9086 - val_loss: 2.9919 - val_accuracy: 0.5524\n",
            "Epoch 49/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2479 - accuracy: 0.9103 - val_loss: 3.1550 - val_accuracy: 0.5518\n",
            "Epoch 50/50\n",
            "1250/1250 [==============================] - 4s 3ms/step - loss: 0.2494 - accuracy: 0.9110 - val_loss: 3.1913 - val_accuracy: 0.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3Iu3KLn_sjV"
      },
      "source": [
        "##### Save and Load Model Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lo7EjMFJ_sjW"
      },
      "source": [
        "#lenet_base.save_weights('./pretrained_model/lenet25.h5')\n",
        "#lenet_base.load_weights('./pretrained_model/lenet25.h5')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4rs0XcZ_sjZ"
      },
      "source": [
        "### Evaluate Prediction & plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFPJPhJD_sja"
      },
      "source": [
        "score = lenet_base.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsZ8fggv_sjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7617e799-e17a-42ce-ea40-0cae54417522"
      },
      "source": [
        "print(score)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.203686237335205, 0.5541999936103821]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IukERBn_sjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c355f889-2e1d-4c41-87a8-51a553149e68"
      },
      "source": [
        "print(score[0], ' : loss')\n",
        "print(score[1]*100, '% : acc')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3.203686237335205  : loss\n",
            "55.41999936103821 % : acc\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojtDWv_sgLtR"
      },
      "source": [
        "### What is happening?\n",
        "\n",
        "\n",
        "**Multi Class Classification though Softmax function** \n",
        "\n",
        "- *Softmax is a generalization of the sigmoid function.*\n",
        "\n",
        "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/bdc1f8eaa8064d15893f1ba6426f20ff8e7149c5)\n",
        "\n",
        "\n",
        "*Steps :*\n",
        "\n",
        "- Raise e (the mathematical constant) to the power of each of those numbers.\n",
        "- Sum up all the exponentials (powers of ee). This result is the denominator.\n",
        "- Use each numbers exponential as its numerator.\n",
        "- $Probability=\\frac{Numerator}{Denominator}$\n",
        "\n",
        "\n",
        "The softmax function squashes all values to the range [0,1] and the sum of the elements is 1.\n",
        "\n",
        "\n",
        "*Example* : \n",
        "\n",
        "Given : -1, 0, 3, 5\n",
        "\n",
        "*We calculate Denominator :* $e^{-1}+e^{0} + e^{3} + e^{5}$ = 169.87\n",
        "\n",
        "*We calculate each Numerator $e^{x}$: * $e^{-1}=0.368, e^{}=1 . . . $\n",
        "\n",
        "*We calculate single probabilities* $ P(\\frac{e^{x}}{Denominator}) $ : $0.368/169.87 = 0.002, 1/169.87= 0.006 . . \n",
        "\n",
        "**Bigger x : bigger Probability**\n",
        "\n",
        "*Try to calculate all values probabilities and sum each other, what is the final number?*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiiBF39OdzqH"
      },
      "source": [
        "### Any other idea??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK5gmRFdd2PY",
        "outputId": "3282ed6f-e10e-4042-cf15-01978a397c99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred1 = lenet_base.predict(x_test)\n",
        "print(classification_report(y_test.argmax(axis=1),\n",
        "                            y_pred1.argmax(axis=1)))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.13      0.23     10000\n",
            "           1       0.00      0.00      0.00         0\n",
            "           2       0.00      0.00      0.00         0\n",
            "           3       0.00      0.00      0.00         0\n",
            "           4       0.00      0.00      0.00         0\n",
            "           5       0.00      0.00      0.00         0\n",
            "           6       0.00      0.00      0.00         0\n",
            "           7       0.00      0.00      0.00         0\n",
            "           8       0.00      0.00      0.00         0\n",
            "           9       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.13     10000\n",
            "   macro avg       0.10      0.01      0.02     10000\n",
            "weighted avg       1.00      0.13      0.23     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl1tAh3iKRqa"
      },
      "source": [
        "## Graphical Evaluation\n",
        "\n",
        "#### First Way!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKkbYsnIKZfG"
      },
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppynwLHwLRUA"
      },
      "source": [
        "```\n",
        "A brief overview of the dashboards shown (tabs in top navigation bar):\n",
        "```\n",
        "- The **Scalars** dashboard shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values.\n",
        "\n",
        "- The **Graphs** dashboard helps you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly.\n",
        "\n",
        "- The **Distributions** and Histograms dashboards show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way.\n",
        "\n",
        "\n",
        "Additional TensorBoard plugins are automatically enabled when you log other types of data. For example, the Keras TensorBoard callback lets you log images and embeddings as well. You can see what other plugins are available in TensorBoard by clicking on the \"inactive\" dropdown towards the top right.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXHvKtUcKbwE"
      },
      "source": [
        "#### Second Way!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4qY4gxi_sjj"
      },
      "source": [
        "def SHOWPREDICTION(orig, model):\n",
        "    import matplotlib.pyplot as plt\n",
        "    \n",
        "    try:\n",
        "        img_class = model.predict_classes(orig[:5])\n",
        "    except AttributeError:\n",
        "        y_pred1 = model.predict(orig[:5])\n",
        "        img_class = np.argmax(y_pred1,axis=1)\n",
        "        \n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    for i in range(5):\n",
        "        # display original\n",
        "        ax = plt.subplot(2, 5, i+1)\n",
        "        plt.imshow(orig[i].reshape(32, 32, 3))\n",
        "        ax.get_xaxis().set_visible(False)\n",
        "        ax.get_yaxis().set_visible(False)\n",
        "        label_name = load_label_names()\n",
        "        plt.title(label_name[i])\n",
        "\n",
        "    plt.show()\n",
        "  \n",
        "def load_label_names():\n",
        "    return ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6tm5JAh_sjm"
      },
      "source": [
        "labelNames = np.array(load_label_names())\n",
        "\n",
        "# How CNN Classifies an Image?\n",
        "img_idx = 122\n",
        "plt.imshow(x_test[img_idx],aspect='auto')\n",
        "print('Actual label:', labelNames[np.argmax(y_test[img_idx])])\n",
        "# Preper image to predict\n",
        "test_image =np.expand_dims(x_test[img_idx], axis=0)\n",
        "print('Input image shape:',test_image.shape)\n",
        "print('Predict Label:',labelNames[lenet_base.predict_classes(test_image,batch_size=1)[0]])\n",
        "print('\\nPredict Probability:\\n', lenet_base.predict_proba(test_image,batch_size=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldYQMhzO_sjp"
      },
      "source": [
        "SHOWPREDICTION(x_test, model=lenet_base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5urKaEKB_sjs"
      },
      "source": [
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['accuracy'])+1),model_history.history['accuracy'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_accuracy'])+1),model_history.history['val_accuracy'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['accuracy'])+1),len(model_history.history['accuracy'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouRz8MHd_sjv"
      },
      "source": [
        "# ---> TRAINED WITH 50 epochs <----\n",
        "plot_model_history(history_lenet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xflSiRT5_sjy"
      },
      "source": [
        "## How appears our training history?\n",
        "\n",
        "![](https://miro.medium.com/max/1125/1*_7OPgojau8hkiPUiHoGK_w.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vB8z1I8Y_sjz"
      },
      "source": [
        "    First of all.. train a lot of time..\n",
        "    \n",
        "    But, this isn't enought!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHL75TbV_sj0"
      },
      "source": [
        "# ---> TRAINED WITH 50 epochs <----\n",
        "plot_model_history(history_lenet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boj2pwc6_sj3"
      },
      "source": [
        "![](https://github.com/matteoalberti/Lectures_introCV_Experis2020/blob/main/images/lenet_50.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pco3pPh-_sj3"
      },
      "source": [
        "##### But adding epochs doesn't resolve everything.. how can we improve performances?\n",
        "    \n",
        "    Two possible ways:\n",
        "    - work with model (An example : Dropout)\n",
        "    - work with data  (An example : Data Augmentation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDj8htJJ_sj_"
      },
      "source": [
        "## Improve Model performances\n",
        "\n",
        "![](https://d3i71xaburhd42.cloudfront.net/fd66fae4891a7993a66ca98fcdc8ce2207bee8b8/4-Figure2-1.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf8b112z_skA"
      },
      "source": [
        "#### Exercise :\n",
        "\n",
        "- play with LeNet\n",
        "    - Change hyperparameters, optimizers, receipt fiels and evaluate the performance.\n",
        "    - *Keep your best model. We'll use it later :)*\n",
        "    \n",
        "Sometime you will have to debug.. remember : debugging neural networks isn't like debugging \"standard\" code. Most of the time *the solution is hidden behind theory*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCIS0Uhn_skA"
      },
      "source": [
        "def build_Lenet_test(height,width,channel,dropout,classes):\n",
        "    \n",
        "    return tf.keras.models.Sequential([])\n",
        "    \n",
        "    \"\"\"\n",
        "    --> Keep fixed other hyperparameters. \n",
        "        You need to be able to compare this architectures\n",
        "        (but later this will not properly manteined)\n",
        "    \n",
        "    \n",
        "    ----> try not to look above <----\n",
        "    \n",
        "    1) try different epochs / batch size - are there any kind of limits?\n",
        "    2) try different optimizers - evaluate how fast converge\n",
        "    \n",
        "    ... \n",
        "    \n",
        "    3) try to change the receipt field (pay attention!)\n",
        "    \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "# build network\n",
        "lenet_test = build_Lenet_test(height=args.height, width=args.width, \n",
        "                          channel=args.channel,\n",
        "                          classes=args.classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CBOFozy_skD"
      },
      "source": [
        "### [Work with Model] Define Dropout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv5Sg-H3_skD"
      },
      "source": [
        "![](https://miro.medium.com/max/1044/1*iWQzxhVlvadk6VAJjsgXgg.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Lxk8i_U_skE"
      },
      "source": [
        "Dropout is a regularization technique for deep neural\n",
        "networks, where it follows the Bernoulli distribution to decide\n",
        "which node to keep or drop.\n",
        "- Different DNNs can be obtained by using dropout for every layer\n",
        "during training as well as testing, and it has been shown that they\n",
        "are mathematically equivalent to samples from a BDNNs.\n",
        "\n",
        "**Pros :**\n",
        " It is easy to turn an existing deep net into a Bayesian one. it is faster than\n",
        "other techniques, and does not require an inference framework.\n",
        "\n",
        "**Cons :**\n",
        " Sampling at test time might be too expensive for computationally\n",
        "demanding (eg real time) applications."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F23hgVPV_skF"
      },
      "source": [
        "![](https://github.com/matteoalberti/Lectures_introCV_Experis2020/blob/main/images/dropout2.png?raw=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRu37RNb_skG"
      },
      "source": [
        "#### Develop New Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pG4IWkT0_skG"
      },
      "source": [
        "# Choose your best architecture and retrain with a Dropout!\n",
        "\n",
        "def build_Lenet_dp(height,width,channel,dropout,classes):\n",
        "    \n",
        "    return tf.keras.models.Sequential([\n",
        "    \n",
        "    tf.keras.layers.Conv2D(6, (5, 5), \n",
        "                     padding='valid', \n",
        "                     activation = 'relu', \n",
        "                     kernel_initializer='he_normal',\n",
        "                     input_shape=(height,width,channel)),\n",
        "\n",
        "    # DROPOUT \n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Conv2D(16, (5, 5), padding='valid', \n",
        "                     activation = 'relu', \n",
        "                     kernel_initializer='he_normal'),\n",
        "    \n",
        "    tf.keras.layers.MaxPooling2D((2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(120, activation = 'relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(84, activation = 'relu', kernel_initializer='he_normal'),\n",
        "    tf.keras.layers.Dense(classes, activation = 'softmax', \n",
        "                    kernel_initializer='he_normal')])\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "# build network\n",
        "lenet_dp = build_Lenet_dp(height=args.height, width=args.width, \n",
        "                          channel=args.channel, dropout=args.dropout,\n",
        "                          classes=args.classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeEIQbUy_skJ"
      },
      "source": [
        "# COMPILE\n",
        "\n",
        "\n",
        "# TRAIN\n",
        "\n",
        "\n",
        "# EVALUATE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDDwcE1LR1Nb"
      },
      "source": [
        "*Any improvments?*\n",
        "\n",
        "- accuracy :\n",
        "- loss :\n",
        "- time to execution :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tU4uqdY_skW"
      },
      "source": [
        "### [Work with Data] Develop data augmentation\n",
        "\n",
        "<div>\n",
        "<img src=\"https://paperswithcode.com/media/tasks/rsz_screenshot_2019-11-29_at_122132_S80u6gv.png\" width=\"500\"/>\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/732/1*WboGzP5KP12n0hdPRN0JsQ.png\" width=\"500\"/>\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auxB550o_skX"
      },
      "source": [
        "Pay attention with Data Augmentation:\n",
        "\n",
        "- Need some extra time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qELjuxyVA5M"
      },
      "source": [
        "### Set-up Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kL9Vct-z-sLH"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncSOC13G_skY"
      },
      "source": [
        "# set up image augmentation\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    horizontal_flip=True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        "    #zoom_range=0.3\n",
        "    )\n",
        "\n",
        "datagen.fit(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U9OtDuJ_skb"
      },
      "source": [
        "# see example augmentation images\n",
        "plt.figure(figsize=(6, 6))\n",
        "for X_batch, y_batch in datagen.flow(x_train, y_train, batch_size=9):\n",
        "    for i in range(0, 9):\n",
        "        plt.subplot(330 + 1 + i)\n",
        "        plt.imshow(X_batch[i].astype(np.uint8))\n",
        "    plt.show()\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2RQatkO_ske"
      },
      "source": [
        "## Retrain our best model with [DA]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "hUGOTcEY_skf"
      },
      "source": [
        "# start train \n",
        "history_lenet_dp_da = lenet_base.fit_generator(datagen.flow(x_train, y_train,batch_size=args.batch_size),\n",
        "                    steps_per_epoch=args.iter,\n",
        "                    epochs=args.epochs*2,\n",
        "                    callbacks=cbks,\n",
        "                    validation_data=(x_test, y_test), verbose=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz6BPRzX_skh"
      },
      "source": [
        "labelNames = np.array(load_label_names())\n",
        "\n",
        "# How CNN Classifies an Image?\n",
        "img_idx = 122\n",
        "plt.imshow(x_test[img_idx],aspect='auto')\n",
        "print('Actual label:', labelNames[np.argmax(y_test[img_idx])])\n",
        "# Preper image to predict\n",
        "test_image =np.expand_dims(x_test[img_idx], axis=0)\n",
        "print('Input image shape:',test_image.shape)\n",
        "print('Predict Label:',labelNames[lenet_dp.predict_classes(test_image,batch_size=1)[0]])\n",
        "print('\\nPredict Probability:\\n', lenet_dp.predict_proba(test_image,batch_size=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enO5-hAV_skl"
      },
      "source": [
        "plot_model_history(history_lenet_dp)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "why-bfk7WQ99"
      },
      "source": [
        "## *Try with lenet + dropout + data augmentation!!*\n",
        "\n",
        "- Accuracy :\n",
        "- Loss :\n",
        "- Time :\n",
        "\n",
        "- Plot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etYnofGmXTAN"
      },
      "source": [
        "## Wanna see an interactive session during training? \n",
        "\n",
        "*Check this link!*\n",
        "\n",
        "https://cs.stanford.edu/people/karpathy/convnetjs/demo/cifar10.html"
      ]
    }
  ]
}